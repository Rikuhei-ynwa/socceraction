{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:23.505616Z",
     "iopub.status.busy": "2023-12-30T16:23:23.504959Z",
     "iopub.status.idle": "2023-12-30T16:23:23.929105Z",
     "shell.execute_reply": "2023-12-30T16:23:23.928396Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:23.932302Z",
     "iopub.status.busy": "2023-12-30T16:23:23.931947Z",
     "iopub.status.idle": "2023-12-30T16:23:24.659342Z",
     "shell.execute_reply": "2023-12-30T16:23:24.658769Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# 現在のファイルのディレクトリを取得\n",
    "current_directory = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# 親ディレクトリを取得\n",
    "parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "\n",
    "# 親ディレクトリをPythonのモジュール検索パスに追加\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "import socceraction.vaep.features as fs\n",
    "import socceraction.vaep.labels as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_date = 202406141613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:24.662351Z",
     "iopub.status.busy": "2023-12-30T16:23:24.662127Z",
     "iopub.status.idle": "2023-12-30T16:23:24.687448Z",
     "shell.execute_reply": "2023-12-30T16:23:24.686865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure file and folder names\n",
    "datafolder = f\"../data-euro2020/{experiment_date}\"\n",
    "spadl_h5 = os.path.join(datafolder, \"spadl-statsbomb.h5\")\n",
    "features_h5 = os.path.join(datafolder, \"features.h5\")\n",
    "labels_h5 = os.path.join(datafolder, \"labels.h5\")\n",
    "predictions_h5 = os.path.join(datafolder, \"predictions.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:24.690119Z",
     "iopub.status.busy": "2023-12-30T16:23:24.689947Z",
     "iopub.status.idle": "2023-12-30T16:23:25.973479Z",
     "shell.execute_reply": "2023-12-30T16:23:25.972930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of games: 51\n"
     ]
    }
   ],
   "source": [
    "games = pd.read_hdf(spadl_h5, \"games\")\n",
    "print(\"nb of games:\", len(games))\n",
    "\n",
    "# note: only for the purpose of this example and due to the small dataset,\n",
    "# we use the same data for training and evaluation\n",
    "traingames = games\n",
    "testgames = games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:25.975644Z",
     "iopub.status.busy": "2023-12-30T16:23:25.975350Z",
     "iopub.status.idle": "2023-12-30T16:23:31.134113Z",
     "shell.execute_reply": "2023-12-30T16:23:31.133562Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting features: 100%|██████████| 51/51 [00:10<00:00,  4.85it/s]\n",
      "Selecting label: 100%|██████████| 51/51 [00:00<00:00, 74.94it/s]\n",
      "Selecting features: 100%|██████████| 51/51 [00:09<00:00,  5.38it/s]\n",
      "Selecting label: 100%|██████████| 51/51 [00:00<00:00, 95.79it/s]\n",
      "Selecting features: 100%|██████████| 51/51 [00:09<00:00,  5.49it/s]\n",
      "Selecting label: 100%|██████████| 51/51 [00:00<00:00, 88.47it/s]\n",
      "Selecting features: 100%|██████████| 51/51 [00:08<00:00,  5.75it/s]\n",
      "Selecting label: 100%|██████████| 51/51 [00:00<00:00, 89.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Select feature set X\n",
    "xfns = [\n",
    "    fs.actiontype,\n",
    "    fs.actiontype_onehot,\n",
    "    fs.bodypart_onehot,\n",
    "    fs.startlocation,\n",
    "    fs.endlocation,\n",
    "    fs.movement,\n",
    "    fs.space_delta,\n",
    "    fs.team,\n",
    "    fs.time_delta,\n",
    "    fs.player_loc_dist,\n",
    "]\n",
    "nb_prev_actions = 1\n",
    "\n",
    "Xcols = fs.feature_column_names(xfns, nb_prev_actions)\n",
    "\n",
    "Xcols_vaep = Xcols\n",
    "\n",
    "Xcols_vdep = [col for col in Xcols_vaep if \"type\" not in col]\n",
    "\n",
    "def getXY(games, features_h5, labels_h5, Xcols, vaep=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    games: pd.DataFrame, \n",
    "        the games that you want to select.\n",
    "    features_h5: str, \n",
    "        the path of the h5 file that contains the features.\n",
    "    labels_h5: str, \n",
    "        the path of the h5 file that contains the labels.\n",
    "    Xcols: list, \n",
    "        the columns of the features that you want to select.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: pd.DataFrame, \n",
    "        the selected features.\n",
    "    Y: pd.DataFrame, \n",
    "        the selected labels.\n",
    "    drop_index: list, \n",
    "        the index of the rows that are dropped.\n",
    "    \"\"\"\n",
    "    # generate the columns of the selected features and labels\n",
    "    X = []\n",
    "    for game_id in tqdm.tqdm(\n",
    "        games.game_id, desc=\"Selecting features\"\n",
    "        ):\n",
    "        Xi = pd.read_hdf(features_h5, f\"game_{game_id}\")\n",
    "        X.append(Xi[Xcols])\n",
    "    X = pd.concat(X).reset_index(drop=True)\n",
    "\n",
    "    if vaep:\n",
    "        Ycols = [\"scores\", \"concedes\"]\n",
    "    else:\n",
    "        Ycols = [\"gains\", \"effective_attack\"]\n",
    "    Y = []\n",
    "    for game_id in tqdm.tqdm(\n",
    "        games.game_id, desc=\"Selecting label\"\n",
    "        ):\n",
    "        Yi = pd.read_hdf(labels_h5, f\"game_{game_id}\")\n",
    "        Y.append(Yi[Ycols])\n",
    "    Y = pd.concat(Y).reset_index(drop=True)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "trainX_vaep, trainY_vaep = getXY(\n",
    "    traingames, features_h5, labels_h5, Xcols_vaep, vaep=True\n",
    "    )\n",
    "trainX_vdep, trainY_vdep = getXY(\n",
    "    traingames, features_h5, labels_h5, Xcols_vdep, vaep=False\n",
    "    )\n",
    "testX_vaep, testY_vaep = getXY(\n",
    "    testgames, features_h5, labels_h5, Xcols_vaep, vaep=True\n",
    "    )\n",
    "testX_vdep, testY_vdep = getXY(\n",
    "    testgames, features_h5, labels_h5, Xcols_vdep, vaep=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113010, 124) (113010, 2)\n",
      "Index(['actiontype_a0', 'actiontype_pass_a0', 'actiontype_cross_a0',\n",
      "       'actiontype_throw_in_a0', 'actiontype_freekick_crossed_a0',\n",
      "       'actiontype_freekick_short_a0', 'actiontype_corner_crossed_a0',\n",
      "       'actiontype_corner_short_a0', 'actiontype_take_on_a0',\n",
      "       'actiontype_offensive_foul_a0',\n",
      "       ...\n",
      "       'dist_dfd9_a0', 'angle_dfd9_a0', 'atk10_x_a0', 'atk10_y_a0',\n",
      "       'dist_atk10_a0', 'angle_atk10_a0', 'dfd10_x_a0', 'dfd10_y_a0',\n",
      "       'dist_dfd10_a0', 'angle_dfd10_a0'],\n",
      "      dtype='object', length=124)\n"
     ]
    }
   ],
   "source": [
    "print(trainX_vaep.shape, trainY_vaep.shape)\n",
    "print(trainX_vaep.columns)\n",
    "print(trainY_vaep.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113010, 99) (113010, 2)\n",
      "Index(['bodypart_foot_a0', 'bodypart_head_a0', 'bodypart_other_a0',\n",
      "       'bodypart_head/other_a0', 'start_x_a0', 'start_y_a0', 'end_x_a0',\n",
      "       'end_y_a0', 'dx_a0', 'dy_a0', 'movement_a0', 'atk0_x_a0', 'atk0_y_a0',\n",
      "       'dist_atk0_a0', 'angle_atk0_a0', 'dfd0_x_a0', 'dfd0_y_a0',\n",
      "       'dist_dfd0_a0', 'angle_dfd0_a0', 'atk1_x_a0', 'atk1_y_a0',\n",
      "       'dist_atk1_a0', 'angle_atk1_a0', 'dfd1_x_a0', 'dfd1_y_a0',\n",
      "       'dist_dfd1_a0', 'angle_dfd1_a0', 'atk2_x_a0', 'atk2_y_a0',\n",
      "       'dist_atk2_a0', 'angle_atk2_a0', 'dfd2_x_a0', 'dfd2_y_a0',\n",
      "       'dist_dfd2_a0', 'angle_dfd2_a0', 'atk3_x_a0', 'atk3_y_a0',\n",
      "       'dist_atk3_a0', 'angle_atk3_a0', 'dfd3_x_a0', 'dfd3_y_a0',\n",
      "       'dist_dfd3_a0', 'angle_dfd3_a0', 'atk4_x_a0', 'atk4_y_a0',\n",
      "       'dist_atk4_a0', 'angle_atk4_a0', 'dfd4_x_a0', 'dfd4_y_a0',\n",
      "       'dist_dfd4_a0', 'angle_dfd4_a0', 'atk5_x_a0', 'atk5_y_a0',\n",
      "       'dist_atk5_a0', 'angle_atk5_a0', 'dfd5_x_a0', 'dfd5_y_a0',\n",
      "       'dist_dfd5_a0', 'angle_dfd5_a0', 'atk6_x_a0', 'atk6_y_a0',\n",
      "       'dist_atk6_a0', 'angle_atk6_a0', 'dfd6_x_a0', 'dfd6_y_a0',\n",
      "       'dist_dfd6_a0', 'angle_dfd6_a0', 'atk7_x_a0', 'atk7_y_a0',\n",
      "       'dist_atk7_a0', 'angle_atk7_a0', 'dfd7_x_a0', 'dfd7_y_a0',\n",
      "       'dist_dfd7_a0', 'angle_dfd7_a0', 'atk8_x_a0', 'atk8_y_a0',\n",
      "       'dist_atk8_a0', 'angle_atk8_a0', 'dfd8_x_a0', 'dfd8_y_a0',\n",
      "       'dist_dfd8_a0', 'angle_dfd8_a0', 'atk9_x_a0', 'atk9_y_a0',\n",
      "       'dist_atk9_a0', 'angle_atk9_a0', 'dfd9_x_a0', 'dfd9_y_a0',\n",
      "       'dist_dfd9_a0', 'angle_dfd9_a0', 'atk10_x_a0', 'atk10_y_a0',\n",
      "       'dist_atk10_a0', 'angle_atk10_a0', 'dfd10_x_a0', 'dfd10_y_a0',\n",
      "       'dist_dfd10_a0', 'angle_dfd10_a0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(trainX_vdep.shape, trainY_vdep.shape)\n",
    "print(trainX_vdep.columns)\n",
    "print(trainY_vdep.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss, confusion_matrix, f1_score, log_loss, roc_auc_score\n",
    "\n",
    "def evaluate(y, y_hat):\n",
    "    p = sum(y) / len(y)\n",
    "    base = [p] * len(y)\n",
    "    brier = brier_score_loss(y, y_hat)\n",
    "    print(f\"  Brier score: %.5f (%.5f)\" % (brier, brier / brier_score_loss(y, base)))\n",
    "    ll = log_loss(y, y_hat)\n",
    "    print(f\"  log loss score: %.5f (%.5f)\" % (ll, ll / log_loss(y, base)))\n",
    "    print(f\"  ROC AUC: %.5f\" % roc_auc_score(y, y_hat))\n",
    "    y_hat_bi = y_hat.round()\n",
    "    print(f\"F1 score:{f1_score(y, y_hat_bi)}\")\n",
    "    print(confusion_matrix(y, y_hat_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:31.135967Z",
     "iopub.status.busy": "2023-12-30T16:23:31.135797Z",
     "iopub.status.idle": "2023-12-30T16:23:32.601027Z",
     "shell.execute_reply": "2023-12-30T16:23:32.600495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Y: scores ###\n",
      "  Brier score: 0.01014 (0.97085)\n",
      "  log loss score: 0.36551 (6.24333)\n",
      "  ROC AUC: 0.52343\n",
      "F1 score:0.0890302066772655\n",
      "[[111808      9]\n",
      " [  1137     56]]\n",
      "### Y: concedes ###\n",
      "  Brier score: 0.00184 (0.89455)\n",
      "  log loss score: 0.06634 (4.47941)\n",
      "  ROC AUC: 0.56864\n",
      "F1 score:0.23529411764705882\n",
      "[[112770      7]\n",
      " [   201     32]]\n",
      "### Y: gains ###\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_proba contains values greater than 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m Y_hat[col] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(trainX_vdep)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestY_vdep\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_hat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(y, y_hat)\u001b[0m\n\u001b[1;32m      4\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(y) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m      5\u001b[0m base \u001b[38;5;241m=\u001b[39m [p] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m----> 6\u001b[0m brier \u001b[38;5;241m=\u001b[39m \u001b[43mbrier_score_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Brier score: %.5f (%.5f)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (brier, brier \u001b[38;5;241m/\u001b[39m brier_score_loss(y, base)))\n\u001b[1;32m      8\u001b[0m ll \u001b[38;5;241m=\u001b[39m log_loss(y, y_hat)\n",
      "File \u001b[0;32m~/workspace5/work/socceraction/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace5/work/socceraction/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:3248\u001b[0m, in \u001b[0;36mbrier_score_loss\u001b[0;34m(y_true, y_proba, sample_weight, pos_label, y_prob)\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly binary classification is supported. The type of the target \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3245\u001b[0m     )\n\u001b[1;32m   3247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_proba\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 3248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_proba contains values greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_proba\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_proba contains values less than 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: y_proba contains values greater than 1."
     ]
    }
   ],
   "source": [
    "# 3. train classifiers F(X) = Y\n",
    "import xgboost\n",
    "\n",
    "Y_hat = pd.DataFrame()\n",
    "models = {}\n",
    "for col in list(trainY_vaep.columns):\n",
    "    model = xgboost.XGBClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=3,\n",
    "        n_jobs=-3,\n",
    "        verbosity=1,\n",
    "        random_state=0,\n",
    "        enable_categorical=True\n",
    "        )\n",
    "    model.fit(trainX_vaep, trainY_vaep[col])\n",
    "    models[col] = model\n",
    "    Y_hat[col] = model.predict(trainX_vaep)\n",
    "    print(f\"### Y: {col} ###\")\n",
    "    evaluate(testY_vaep[col], Y_hat[col])\n",
    "\n",
    "for col in list(trainY_vdep.columns):\n",
    "    model = xgboost.XGBClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=3, \n",
    "        n_jobs=-3, \n",
    "        verbosity=1, \n",
    "        random_state=0,\n",
    "        enable_categorical=True\n",
    "        )\n",
    "    model.fit(trainX_vdep, trainY_vdep[col])\n",
    "    models[col] = model\n",
    "    Y_hat[col] = model.predict(trainX_vdep)\n",
    "    print(f\"### Y: {col} ###\")\n",
    "    evaluate(testY_vdep[col], Y_hat[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T16:23:33.565897Z",
     "iopub.status.busy": "2023-12-30T16:23:33.565730Z",
     "iopub.status.idle": "2023-12-30T16:23:34.539659Z",
     "shell.execute_reply": "2023-12-30T16:23:34.539155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading game ids: 100%|██████████| 51/51 [00:03<00:00, 14.95it/s]\n",
      "Saving predictions per game: 100%|██████████| 51/51 [00:00<00:00, 131.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# get rows with game id per action\n",
    "A = []\n",
    "for game_id in tqdm.tqdm(games.game_id, \"Loading game ids\"):\n",
    "    Ai = pd.read_hdf(spadl_h5, f\"actions/game_{game_id}\")\n",
    "    A.append(Ai[[\"game_id\"]])\n",
    "A = pd.concat(A)\n",
    "A = A.reset_index(drop=True)\n",
    "\n",
    "# concatenate action game id rows with predictions and save per game\n",
    "grouped_predictions = pd.concat([A, Y_hat], axis=1).groupby(\"game_id\")\n",
    "with pd.HDFStore(predictions_h5) as predictionstore:\n",
    "    for k, df in tqdm.tqdm(grouped_predictions, desc=\"Saving predictions per game\"):\n",
    "        df = df.reset_index(drop=True)\n",
    "        predictionstore.put(f\"game_{int(k)}\", df[Y_hat.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113081\n",
      "112447\n"
     ]
    }
   ],
   "source": [
    "print(112869+1+105+106)\n",
    "print(112208+6+204+29)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
